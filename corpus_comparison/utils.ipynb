{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c9b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def construct_dict(total_sens):\n",
    "    lexicon_dic = {}\n",
    "    stop_words = stopwords.words('english')\n",
    "    lema = WordNetLemmatizer()\n",
    "    for s in total_sens:\n",
    "        analyze = nltk.pos_tag(s)\n",
    "        # print(analyze)\n",
    "        for i, a in enumerate(analyze):\n",
    "            if a[1].startswith('JJ') or a[1].startswith('RB') or a[1].startswith('NN') or a[1].startswith('V') or a[1].startswith('MD'):\n",
    "            # if a[1].startswith('V'):\n",
    "                if a[0] not in stop_words and a[0] != 'al': \n",
    "                    word = lema.lemmatize(a[0])\n",
    "                    if word not in lexicon_dic.keys():\n",
    "                        lexicon_dic[word] = 1\n",
    "                    else:\n",
    "                        lexicon_dic[word] += 1\n",
    "    # combine uppercase to lowercase word if more frequent            \n",
    "    to_delete = []\n",
    "    for k in lexicon_dic.keys():\n",
    "        original = lexicon_dic[k]\n",
    "        if k.lower() in lexicon_dic:\n",
    "            lower = lexicon_dic[k.lower()]\n",
    "            if lower > original:\n",
    "                to_delete.append(k)\n",
    "\n",
    "    for td in to_delete:\n",
    "        to_add = lexicon_dic[td]\n",
    "        del lexicon_dic[td]\n",
    "        lexicon_dic[td.lower()] += to_add\n",
    "        \n",
    "    return lexicon_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57dda6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric(find_opinion, opinion_answer, sens_length):\n",
    "    TP_of_opinion = 0\n",
    "    for fo in find_opinion:\n",
    "        if fo in opinion_answer:\n",
    "            TP_of_opinion += 1\n",
    "        \n",
    "    FP_of_opinion = len(find_opinion) - TP_of_opinion\n",
    "\n",
    "    FN_of_opinion = 0\n",
    "    for oa in opinion_answer:\n",
    "        if oa not in find_opinion:\n",
    "            FN_of_opinion += 1\n",
    "    TN_of_opinion = sens_length - TP_of_opinion - FP_of_opinion - FN_of_opinion\n",
    "\n",
    "    Accuracy = (TP_of_opinion+TN_of_opinion)/sens_length\n",
    "    Precision = TP_of_opinion/(TP_of_opinion+FP_of_opinion)\n",
    "    Recall = TP_of_opinion/(TP_of_opinion+FN_of_opinion)\n",
    "    F1_Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "\n",
    "    return Precision, Recall, F1_Score, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2eec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
